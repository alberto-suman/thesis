{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"conv3d + lstm.ipynb","provenance":[{"file_id":"1BjDIKzj8A6wV-mLr_GDZSD2-QFWZGGfK","timestamp":1579779727804}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"swMC1SE3Cdu-","colab_type":"text"},"source":["#Setting environment (necessary after restarting runtime)"]},{"cell_type":"markdown","metadata":{"id":"Xe8aqQ6laeQc","colab_type":"text"},"source":["Ho dovuto installare la versione 2.0 perch√© la versione 2.1 ha problemi con la gpu"]},{"cell_type":"code","metadata":{"id":"y9y49WZW-LJk","colab_type":"code","cellView":"both","outputId":"4d433b0f-5b4c-45e8-937b-c2b14cad698e","executionInfo":{"status":"ok","timestamp":1581431805373,"user_tz":-60,"elapsed":8212,"user":{"displayName":"Alberto Suman","photoUrl":"","userId":"05935241068502951875"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title Selecting tensorflow version 2\n","#%tensorflow_version 2.x\n","!pip install -q tensorflow==2.0\n","import tensorflow as tf\n","tf.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"rQDgcnvlr75c","colab_type":"code","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4e326337-ce6b-4285-81d2-06dd7a5b18e0","executionInfo":{"status":"ok","timestamp":1581431805374,"user_tz":-60,"elapsed":7445,"user":{"displayName":"Alberto Suman","photoUrl":"","userId":"05935241068502951875"}}},"source":["#@title Mounting Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o0xfUlns6BY3","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Importing things and defining functions\n","import sys\n","from tensorflow import keras\n","import numpy as np\n","import cv2 as cv\n","import tensorflow_datasets as tfds\n","import datetime\n","import time\n","import tensorflow as tf\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zD99-YiZztAe","colab_type":"text"},"source":["### Functions"]},{"cell_type":"code","metadata":{"id":"sHx-rqh-zsB9","colab_type":"code","cellView":"form","colab":{}},"source":["#@title To display videos\n","import imageio\n","from IPython import display\n","\n","def animate(images):\n","  converted_images = np.clip(images, 0, 255).astype(np.uint8)\n","  imageio.mimsave('./animation.gif', converted_images, fps=25)\n","  with open('./animation.gif','rb') as f:\n","        display.display(display.Image(data=f.read(), height=300))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXgP6x0jRtBN","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Pipeline functions\n","# function graph-enabled\n","def sampling(video, number_of_frames=20):\n","    result = tf.Variable(np.zeros((number_of_frames, 256, 256, 3), dtype=np.float16))\n","    for i in range(number_of_frames):\n","        result[i].assign(video[i])\n","    print(result)\n","    return result\n","\n","# function that creates packets of frames\n","def pack_resize_frames(video):\n","    framesPerPacket = 5\n","    samplingFactor = 3\n","    numPackets = int(video.shape[0]//(framesPerPacket * samplingFactor))\n","    result = [] * numPackets\n","    for j in range(numPackets):\n","        offset = tf.random.uniform([framesPerPacket], 0, samplingFactor, tf.dtypes.int32)\n","        temp = [] * framesPerPacket\n","        for i in range(framesPerPacket):\n","             temp.append(video[(j * framesPerPacket + i) * samplingFactor + offset[i]])\n","        result.append(tf.image.resize(tf.convert_to_tensor(temp), size=(64,64)))\n","    return tf.convert_to_tensor(result)\n","\n","# function that uses standard python libraries (deprecated)\n","def py_sampling(video, seed_in, number_of_frames=20):\n","    size = video.get_shape()[0]\n","    indexes = tf.random.stateless_truncated_normal(shape=[number_of_frames],\n","                                                   seed=[seed_in, seed_in],\n","                                                   mean=size/2,\n","                                                   stddev=size/4)\n","    indexes = tf.cast(tf.sort(indexes, axis=0, direction='ASCENDING'), tf.uint16)\n","    result = tf.convert_to_tensor(video.numpy()[indexes.numpy()])\n","    return result\n","\n","# casting and normalizing\n","def custom_cast(feature):\n","    video = tf.cast(feature['video'], tf.float16) / 255.\n","    return {'label':feature['label'], 'video':video}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZyWoG_yCWJB","colab_type":"text"},"source":["# Custom layers"]},{"cell_type":"code","metadata":{"id":"pxM4BSP5EC_b","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Custom3DConv\n","class CustomConv3D(keras.layers.Layer):\n","\n","    def __init__(self, filters, kernel_size, **kwargs):\n","        super(CustomConv3D, self).__init__()\n","        self.spatial = keras.layers.Conv3D(filters=filters,\n","                                            kernel_size=(kernel_size, kernel_size, 1),\n","                                            strides=1,\n","                                            padding='same',\n","                                            **kwargs)\n","        self.temporal = keras.layers.Conv3D(filters=filters,\n","                                            kernel_size=(1, 1, kernel_size),\n","                                            strides=1,\n","                                            padding='same',\n","                                            **kwargs)\n","\n","    def __call__(self, inputs):\n","        x = self.spatial(inputs)\n","        outputs = self.temporal(x)\n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLX8dnCajagf","colab_type":"code","cellView":"form","colab":{}},"source":["#@title InceptionBlock\n","class InceptionBlock(keras.layers.Layer):\n","\n","    def __init__(self, filters, kernel_size, **kwargs):\n","        super(InceptionBlock, self).__init__()\n","        self.short = keras.layers.Conv3D(filters=filters,\n","                                         kernel_size=1,\n","                                         strides=1,\n","                                         **kwargs)\n","        self.medium = CustomConv3D(filters=filters,\n","                                   kernel_size=kernel_size,\n","                                   **kwargs)\n","        self.tall = [CustomConv3D(filters=filters,\n","                                   kernel_size=kernel_size,\n","                                   **kwargs),\n","                     CustomConv3D(filters=filters,\n","                                   kernel_size=kernel_size,\n","                                   **kwargs)]\n","        self.concat = keras.layers.Concatenate(axis=-1)\n","        self.pool = keras.layers.MaxPool3D(pool_size=(1,1,3),\n","                                           padding='same',\n","                                           data_format='channels_first')\n","        \n","    def __call__(self, inputs):\n","        x_1 = self.short(inputs)\n","        x_2 = self.medium(inputs)\n","        x_3 = inputs\n","        for layer in self.tall:\n","            x_3 = layer(x_3)\n","        x = self.concat([x_1, x_2, x_3])\n","        outputs = self.pool(x)\n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxiOwRUMDq5V","colab_type":"code","cellView":"form","colab":{}},"source":["#@title ResnetLayer\n","class ResnetLayer(keras.layers.Layer):\n","\n","    def __init__(self, filters, kernel_size, **kwargs):\n","        super(ResnetLayer, self).__init__()\n","        self.block = InceptionBlock(filters=filters,\n","                                        kernel_size=kernel_size,\n","                                        trainable=True,\n","                                        **kwargs)\n","        self.batch = keras.layers.BatchNormalization(axis=-1)\n","\n","    def __call__(self, inputs):\n","        x = self.block(inputs)\n","        x = self.batch(x)\n","        return inputs + x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxa0snHsJIZP","colab_type":"code","cellView":"form","colab":{}},"source":["#@title ResnetBlock\n","class ResnetBlock(keras.layers.Layer):\n","\n","    def __init__(self, blocks, filters, kernel_size, **kwargs):\n","        super(ResnetBlock, self).__init__()\n","        self.blocks = []\n","        for i in range(blocks): \n","            self.blocks.append(ResnetLayer(filters=filters,\n","                                           kernel_size=kernel_size,\n","                                           **kwargs))\n","            \n","    def __call__(self, inputs):\n","        x = inputs\n","        for layer in self.blocks:\n","            x = layer(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aSedJE9vzBqs","colab_type":"text"},"source":["# Loading Dataset and writing to disk"]},{"cell_type":"markdown","metadata":{"id":"OvL4e4Hciwn8","colab_type":"text"},"source":["## Useful functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"B2c940G4ihM_","cellView":"both","colab":{}},"source":["#@title Define functions for value conversion\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LxR3v4KNjA2j","cellView":"both","colab":{}},"source":["#@title Serializing functions\n","def serialize_example(label, video):\n","    feature = {\n","        'label' : _int64_feature(label),\n","        'video' : _bytes_feature(tf.io.serialize_tensor(video))\n","    }\n","\n","    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n","    return example_proto.SerializeToString()\n","\n","def tf_serialize_example(example):\n","    tf_string = tf.py_function(\n","        serialize_example,\n","        [example['label'], example['video']],\n","        tf.string)\n","    return tf.reshape(tf_string, ())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FniOb3OggDYy","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Writing function\n","def write_dataset(dataset, curr, prec):\n","    def filter_fn(x):\n","        frames = tf.shape(x['video'])[0]\n","        return frames <= curr and frames > prec\n","\n","    dataset_temp = dataset.filter(filter_fn)\n","    directory = \"/content/drive/My Drive/splitted_dataset/random_2/pck_{}_{}\".format(prec+1, curr)\n","    filename = os.path.join(directory, \"tfrecord\")\n","    try:\n","        os.mkdir(directory)\n","    except:\n","        print(\"--- Exception: directory already exists\")\n","    serialized_features_dataset = dataset_temp.map(tf_serialize_example)\n","    writer = tf.data.experimental.TFRecordWriter(filename)\n","    writer.write(serialized_features_dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"auLXYBlci1Zf","colab_type":"text"},"source":["## Data reading, pipelining and writing"]},{"cell_type":"code","metadata":{"id":"CktWDTbNBl-z","colab_type":"code","colab":{}},"source":["#@title Get the initial dataset and cache it\n","dataset, info = tfds.load('ucf101',\n","                            with_info=True,\n","                            data_dir=\"/content/drive/My Drive/\",\n","                            download=False,\n","                            split='train')\n","\n","dataset = dataset.map(lambda x: {'video':tf.py_function(func=pack_resize_frames,\n","                                                                        inp=[x['video']],\n","                                                                        Tout=tf.float32),\n","                                                'label':x['label']},\n","                                    num_parallel_calls=4)\n","\n","def filter_whole(x):\n","        frames = tf.shape(x['video'])[0]\n","        return frames > 16\n","\n","#dataset = dataset.filter(filter_whole)\n","\n","dataset = dataset.cache(filename=\"/content/drive/My Drive/temp/whole\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3LVJEHoGer4q","colab_type":"code","outputId":"837f7ffe-36a2-406c-dd83-6da934a4ad6b","executionInfo":{"status":"ok","timestamp":1581431832658,"user_tz":-60,"elapsed":420,"user":{"displayName":"Alberto Suman","photoUrl":"","userId":"05935241068502951875"}},"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#@title Get the number of examples having a certain dimension (already computed and written to a file)\n","count = open(\"drive/My Drive/utils/count.txt\", mode='r')\n","indexes = list(map(lambda x: [int(x.split(\"\\t\")[0]), int(x.split(\"\\t\")[1])], count.readlines()))\n","print(indexes)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[1, 1], [2, 4], [3, 100], [4, 382], [5, 622], [6, 807], [7, 703], [8, 741], [9, 593], [10, 622], [11, 635], [12, 465], [13, 551], [14, 339], [15, 291], [16, 811], [17, 357], [18, 187], [19, 170], [20, 385], [21, 99], [22, 109], [23, 73], [24, 64], [25, 42], [26, 63], [27, 57], [28, 44], [29, 40], [30, 27], [31, 21], [32, 34], [33, 23], [34, 11], [35, 13], [36, 4], [37, 4], [38, 6], [39, 13], [40, 4], [41, 5], [42, 4], [50, 2], [51, 1], [53, 1], [54, 2], [55, 1], [56, 3], [118, 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"95mfY9-D1abv","colab_type":"code","outputId":"03f2e185-f744-4704-ecdc-3e4c8e1bd6eb","executionInfo":{"status":"ok","timestamp":1581346464040,"user_tz":-60,"elapsed":3555,"user":{"displayName":"Alberto Suman","photoUrl":"","userId":"05935241068502951875"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#@title Equally divide the training according to its dimension\n","count = 0\n","prec = 0\n","for i in range(len(indexes)):\n","    count += indexes[i][1]\n","    if count >= 1000 or i == len(indexes)-1:\n","        print(\"Writing dataset having number of packets higher than {} and lower or equal to {} ...\".format(prec, indexes[i][0]))\n","        write_dataset(dataset, indexes[i][0], prec)\n","        print(\"Done!\")\n","        prec = indexes[i][0]\n","        count = 0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Writing dataset having number of packets higher than 0 and lower or equal to 5 ...\n","--- Exception: directory already exists\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3jxqeM1gxHfg","colab_type":"text"},"source":["# Custom models"]},{"cell_type":"markdown","metadata":{"id":"WeXw8LjL60jD","colab_type":"text"},"source":["### Model built with Functional API"]},{"cell_type":"markdown","metadata":{"id":"6oEhhZuyCDQu","colab_type":"text"},"source":["Model built using blocks of resnet layers"]},{"cell_type":"code","metadata":{"colab_type":"code","cellView":"form","id":"2qm4rDVL97eu","colab":{}},"source":["#@title Conv3D and LSTM\n","class MyModel(keras.Model):\n","\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.convLayers = []\n","\n","        self.convLayers.append(keras.layers.Conv3D(filters=8,\n","                                            kernel_size=(1,3,3),\n","                                            strides=(1,2,2),\n","                                            padding='same',\n","                                            activation='relu'))\n","\n","        self.convLayers.append(keras.layers.MaxPool3D(pool_size=(1,2,2)))\n","\n","        self.convLayers.append(ResnetBlock(blocks=2,\n","                                    filters=8,\n","                                    kernel_size=3,\n","                                    activation='relu'))\n","        self.convLayers.append(keras.layers.BatchNormalization(axis=-1))\n","\n","        self.convLayers.append(keras.layers.Conv3D(filters=24,\n","                                            kernel_size=(1,3,3),\n","                                            strides=2,\n","                                            padding='same',\n","                                            activation='relu'))\n","\n","        self.convLayers.append(ResnetBlock(blocks=5,\n","                                    filters=24,\n","                                    kernel_size=3,\n","                                    activation='relu'))\n","        self.convLayers.append(keras.layers.BatchNormalization(axis=-1))\n","\n","        self.convLayers.append(keras.layers.Conv3D(filters=128,\n","                                            kernel_size=(1,3,3),\n","                                            strides=(1,2,2),\n","                                            padding='same',\n","                                            activation='relu'))\n","        \n","        self.convLayers.append(keras.layers.MaxPool3D(pool_size=(2,2,2)))\n","\n","        #self.convLayers.append(keras.layers.MaxPool3D(pool_size=(1,2,2)))\n","        \n","        self.lstmLayer = keras.layers.LSTM(units=101,\n","                                           return_sequences=False,\n","                                           activation='softmax',\n","                                           dtype=tf.float32)\n","        '''\n","        self.denseLayer = keras.layers.Dense(101,\n","                                             activation='softmax',\n","                                             dtype=tf.float32)'''\n","\n","    def call(self, inputs):\n","        convResult = []\n","        for packet in range(self.numPackets):\n","            x = inputs[:, packet]\n","            for layer in self.convLayers:\n","                x = layer(x)\n","            convResult.append(x)\n","        x = tf.stack(convResult, axis=1)\n","        print(\"Output of the conv3D layers {}\".format(x.shape))\n","        new_shape = x.shape[2]*x.shape[3]*x.shape[4]*x.shape[5]\n","        x = keras.layers.Reshape(target_shape=(self.numPackets, new_shape))(x)\n","        print(\"Input of the lstm layer {}\".format(x.shape))\n","        x = self.lstmLayer(x)\n","        #x = self.denseLayer(x)\n","        return x\n","\n","    def setPackets(self, pck):\n","        self.numPackets = pck\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x8c1NjFVXw6j","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"J6_UbKLI51PT","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Setting half precision for GPU\n","tf.keras.backend.set_floatx('float16')\n","loss_scale = 'dynamic'\n","policy = tf.keras.mixed_precision.experimental.Policy(\n","    \"mixed_float16\", loss_scale=loss_scale)\n","tf.keras.mixed_precision.experimental.set_policy(policy)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z74KBR7L4svn","colab_type":"code","outputId":"7b5a00ab-08a4-4ecb-d481-20640e101c2a","executionInfo":{"status":"ok","timestamp":1581334585505,"user_tz":-60,"elapsed":555,"user":{"displayName":"Alberto Suman","photoUrl":"","userId":"05935241068502951875"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["dataset.element_spec"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': TensorSpec(shape=(), dtype=tf.int64, name=None),\n"," 'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"9a9bC650svio","colab_type":"code","outputId":"34af5c1e-3863-4ab3-bb33-007f71bc5595","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["for i in range(4, len(indexes), 4): \n","    def filter_fn(x):\n","        frames = tf.shape(x['video'])[0]\n","        return frames <= i and frames > i-4\n","    \n","    dataset_temp = dataset.filter(filter_fn)\n","    print(dataset_temp.element_spec)\n","    directory = \"/content/drive/My Drive/splitted_dataset/pck={}\".format(i)\n","    filename = directory + \"/tfrecord\"\n","    try:\n","        os.mkdir(directory)\n","    except:\n","        print(\"Directory already exists\")\n","    serialized_features_dataset = dataset_temp.map(tf_serialize_example)\n","\n","    writer = tf.data.experimental.TFRecordWriter(filename)\n","    writer.write(serialized_features_dataset)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n","Directory already exists\n","{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n","{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n","{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n","{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n","{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n","{'video': TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3vpAGz44Q3ZV","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Loading tensorboard\n","board = \"drive/My Drive/tensorboard/tensorboard_logs/conv_lstm\"\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=board,\n","                                                      histogram_freq=1,\n","                                                      update_freq='batch',\n","                                                      profile_batch=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPdZPcPi2Cy5","colab_type":"code","cellView":"both","outputId":"f0dc7b00-e883-4a32-e1e2-35cfafd34c71","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#@title Training\n","# if uncommented uses xla (don't change much)\n","# tf.config.optimizer.set_jit(False)\n","for numPackets in indexes:\n","    print(\"\\nTraining with samples having {} packets of frames\".format(numPackets))\n","    model = MyModel()\n","    model.compile(optimizer='SGD',\n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","    if numPackets != 1:\n","        model.load_weights(\"/content/drive/My Drive/weights/final_model/weights\")\n","    dataset_temp = get_dataset(numPackets)\n","    model.setPackets(numPackets)\n","    for features in dataset_temp:\n","        inputs, targets = features['video'], features['label']\n","        model.fit(x=inputs,\n","                y=targets,\n","                verbose=2,\n","                callbacks=[tensorboard_callback])\n","    model.save_weights(\"/content/drive/My Drive/weights/final_model/weights\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Training with samples having 1 packets of frames\n"],"name":"stdout"}]}]}